# Статьи по мультизадачным и мультимодальным моделям

Создание мультизадачных и мультимодальных моделей в настоящее время – активно развивающая сфера исследований, которая позволяет экономить вычислительные ресурсы и время, необходимое для обучения, а также впоследствии, возможно, приведет к созданию сильного искусственного интеллекта. 

1. [UniT: Multimodal Multitask Learning with a Unified Transformer](https://arxiv.org/pdf/2102.10772.pdf) (Unified Transformer (UniT), ```Hu, Singh, 2021```), который является частью фреймворка [MMF](https://github.com/facebookresearch/mmf) для построения мультимодальных моделей. В экспериментах UniT одновременно обучается на 8 датасетах (MS-COCO, VG, VQAv2, SNLI-VE, QNLI, MNLI-mm, QQP, SST-2) по 7 задачам (в текстовом, визуальном и совместном текстово-визуальном доменах). Модель имеет архитектуру типа «кодировщик-декодировщик» (encoder-decoder): для каждого типа данных (модальностей, в данном случае – текстовой и визуальной) используется свой кодировщик; декодировщик при этом единый для всех задач. Выход декодировщика отправляется в специфическую для конкретного задания «голову» (для всех задач, кроме object detection, она представляет собой двуслойный перцептрон), которая и выдаёт финальное предсказание:

<p align="center">
  <img src="https://dsworks.s3pd01.sbercloud.ru/aij2021/misc/unit.png" width="60%">
</p>

При каждой итерации во время обучения для формирования батча выбирается задание и соответствующий ему датасет; для каждого задания заранее задаётся вероятность сэмплирования. 


2. [Attention Bottlenecks for Multimodal Fusion](https://arxiv.org/abs/2107.00135) (Multimodal Bottleneck Transformer (MBT), `Nagrani, Arsha et al., 2021`) - оригинальный подход к работе с мультимодальными входами (в основном видео и аудио) со средним уровнем слияния.

<p align="center">
  <img src="https://dsworks.s3pd01.sbercloud.ru/aij2021/misc/mid_fuse.png" width="60%">
</p>
Почти все слои обрабатываются трансформатором отдельно, и только рядом с верхним (2-4 слоя)  производится слияние:
    -Шаг А: нейроны модаальности<sub>1</sub> соединияются с небольшим количеством B так называемых мультимодальных bottlenecks (авторы брали B=4) и, затем реализуется self-attention механизм, потом
    -Шаг B: нейроны модаальности<sub>2</sub> соединияются с небольшим количеством B  мультимодальных bottlenecks (соответствующих выходу шагу A) и, затем реализуется self-attention механизм (мдальности<sub>2</sub> + мультимодальные bottlenecks).

<p align="center">
  <img src="https://dsworks.s3pd01.sbercloud.ru/aij2021/misc/mbt.png" width="60%">
</p>
Самое интересное, что обмен мультимодальной информацией происходит через очень узкий информационный bottleneck одновременно без добавления вычислительной сложности.
В качестве трансформера авторы используют ViT-B архитектуру.

3. [Perceiver: General Perception with Iterative Attention](https://arxiv.org/abs/2103.03206) and [Perceiver IO: A General Architecture for Structured Inputs & Outputs](https://arxiv.org/abs/2107.14795) (`Jaegle, Andrew et al., 2021`) - the novel method of dealing with attentions for multi-modal data with linear complexity on either input size or output size. Две основные идеи:
- Iterative attention, когда один и тот же вход может быть передан на разную глубину - как процедура RNN (авторы утверждают, что эта идея лежит в основе работы человеческого мозга) - где параметры трансформеров могут быть общими, и

<p align="center">
  <img src="https://dsworks.s3pd01.sbercloud.ru/aij2021/misc/perceiver.png" width="60%">
</p>

- Cross-attention, когда либо запрос является латентным потоком и ключевые значения являются входными данными (для подачи данных в модель), либо запрос является выходной структурой (например, список позиций пикселей и задание<sub>id</sub>)

<p align="center">
  <img src="https://dsworks.s3pd01.sbercloud.ru/aij2021/misc/perceiverIO.png" width="60%">
</p>
Здесь важно отметить, как вводить информацию вход или выход). Авторы предлагают различные схемы кодирования позиции (включая признаки Фурье) или даже выученную кодировку (так что нет необходимости в явной токенизации).


<p align="center">
  <img src="https://dsworks.s3pd01.sbercloud.ru/aij2021/misc/perceiverIO_emb.png" width="60%">
</p>

Архитектура латентного трансформера GPT-2. 

4. [Multi-Task Deep Neural Network](https://github.com/namisan/mt-dnn) (MT-DNN, ```Liu, He et al., 2019```) – единая модель, созданная для решения различных задач в области понимания естественного языка (NLU). Нижние слои модели едины для всех задач, верхние слои специфичны для каждого типа задания. В качестве кодировщика используется многослойный двунаправленный кодировщик Трансформера – однако, в отличие от BERT, MT-DNN выучивает репрезентации не только с помощью предобучения, но и с помощью мультизадачных целевых функций. 

<p align="center">
  <img src="https://dsworks.s3pd01.sbercloud.ru/aij2021/misc/mt-dnn.png" width="60%">
</p>

Процедура обучения MT-DNN состоит из двух стадий: предобучения и мультизадачного обучения. Во время мультизадачной фазы в каждую эпоху выбирается мини-батч (среди всех 9 заданий GLUE) – и веса модели обновляются согласно целевой функции, использующейся для конкретного задания. Такой подход аппроксимативно оптимизирует сумму целевых функций для всех задач. Авторы подчеркивают, что мультизадачное обучение имеет преимущества за счет эффекта регуляризации (меньший риск переобучения на конкретной задаче) – благодаря этому выученные репрезентации данных получаются более универсальными. MT-DNN обучалась на датасетах SNLI, SciTail и GLUE, решая 4 типа заданий: классификация единичных предложений, классификация пар текстов, оценка близости текстов, ранжирование текстов по релевантности.

5. [OmniNet: A unified architecture for multi-modal multi-task learning](https://arxiv.org/pdf/1907.07804.pdf) (`Pramanik et al., 2020`) — модель [OmniNet](https://github.com/subho406/OmniNet) включает два блока «периферических сетей» (peripheral networks): один кодирует картинки и видео, другой — текстовые данные. В качестве кодировщика изображений и видео используется предобученная сверточная нейросеть ResNet-152. Для кодирования текстов применяются предобученные подсловные эмбеддинги, полученные с помощью BPE. Закодированные данные конкатенируются с эмбеддингами типа данных и поступают в центральный блок (Central Neural Processor). Данные, у которых есть временная размерность, проходят через блок кодировщика; данные, у которых временной размерности нет, подвергаются преобразованию размерности (reshape). Все полученные матрицы сохраняются в кэш, который поступает в блок декодера:

<p align="center">
  <img src="https://dsworks.s3pd01.sbercloud.ru/aij2021/misc/omninet.png" width="70%">
</p>

Предусмотрены эмбеддинги заданий, несколько наборов выходных эмбеддинов для разных типов выходных данных и отдельные классификаторы для разных заданий. Мультизадачность достигается с помощью подхода HogWild: помимо глобальной копии модели, создаются локальные копии для каждого задания; вычисленные локальные градиенты асинхронно копируются в глобальную модель, затем происходит обновление её весов. Модель обучалась на задачах частеречной разметки, генерации ответов на вопросы по изображению, генерации подписей к картинкам и распознавания действий на видео.

6. [12-in-1: Multi-Task Vision and Language Representation Learning](https://arxiv.org/pdf/1912.02315.pdf) (`Lu, Goswami et al., 2020`) — в статье описывается модель, основанная на архитектуре [ViLBERT](https://arxiv.org/pdf/1908.02265.pdf) (`Lu et al., 2019`), в которой текстовые и визуальные входные данные взаимодействуют посредством слоёв co-attention (механизма "взаимного внимания"):

<p align="center">
  <img src="https://dsworks.s3pd01.sbercloud.ru/aij2021/misc/vilbert.png" width="80%">
</p>

Изображение и текст, к которым добавляется соответствующий заданию токен, кодируются с помощью двух блоков, архитектура которых подобна BERT. Эти модули предобучены на задачах предсказания маскированного элемента и предсказания наличия связи между входными данными. Авторы использовали 12 датасетов с задачами, основанных на изображениях и текстах. Эти задачи можно разделить на следующие группы: выбор подходящего ответа на вопрос по изображению, выбор изображения, соответствующего описанию, выбор фрагмента изображения, соответствующего описанию, проверка, соответствуют ли друг другу изображение и текст Для решения этих задач обучено шесть голов модели. При обучении используется предложенный авторами метод stop-and-go, позволяющий приоставливать использование датасетов небольшого объема на большее количество итераций и продолжать использовать большие датасеты. 

7. [M3P: Learning Universal Representations via Multitask Multilingual Multimodal Pre-training](https://arxiv.org/pdf/2006.02635.pdf) (`Ni et al., 2021`) — модель, в которой мультилингвальное предобучение и мультимодальное предобучение комбинируются с помощью мультизадачности в едином фреймворке:

<p align="center">
  <img src="https://dsworks.s3pd01.sbercloud.ru/aij2021/misc/m3p.png" width="80%">
</p>

Мультизадачность интегрирована в стадию предобучения для одновременной оптимизации всех выбранных целевых функций. Сначала модель предобучается на задаче предсказания маскированного токена, при этом используются три типа входных данных: текст на одном языке + изображения; текст, в котором происходит смена языка (Multimodal Code-switched Training); сочетание первых двух случаев. Далее модель дообучается на двух мультилингвальных датасетах, используемых для задачи поиска изображений: Multi30K — расширенная версия Flickr30K (английские, немецкие, французские и чешские подписи) and MS-COCO (английские, китайские и японские подписи). 

8. [HyperGrid Transformers: Towards A Single Model for Multiple Tasks](https://openreview.net/pdf?id=hiq1rHO8pNT) (`Tay et al., 2021`) – авторы предлагают подход, при котором мультизадачное обучение модели обеспечивается благодаря использованию декомпозиционной гиперсети (сети, которая генерирует веса для основной модели), которая выучивает grid-wise проекции, позволяющие выделять отдельные регионы в матрице весов в зависимости от задачи, обеспечивая специализацию подсети. Для построения подобной гиперсети используются локальная (зависящая от примера и задачи) и глобальная (независимая от задачи) проекции: композиция локального и глобального векторов формирует матрицу гейтирования, которая затем расширяется (повтором) до размера матрицы весов Трансформера для получения специфичной для каждого задания матрицы весов:

<p align="center">
  <img src="https://dsworks.s3pd01.sbercloud.ru/aij2021/misc/hypergrid.png" width="80%">
</p>

Авторы проводили эксперименты на бенчмарках GLUE и SuperGLUE (задачи NLP и NLU). В качестве основной модели используется T5, к ней добавляются слои HyperGrid. Результаты демонстрируют, что качество единой модели (Avg 85.0 на GLUE и 73.6 на SuperGLUE) не намного уступает качеству отдельных моделей, дообученных под конкретные задачи (Avg 85.7 на GLUE и 74.8 на SuperGLUE), однако обучение единой архитектуры требует изменения в 16 раз меньшего количества параметров.  

9. [AdapterHub: A Framework for Adapting Transformers](https://arxiv.org/pdf/2007.07779v1.pdf) (`Pfeiffer et al., 2020`) – в статье описывается новый подход к дообучению базовых моделей (foundation models): вместо того, чтобы полностью дообучать тяжеловесные модели, предлагается использовать «адаптеры» – легковесные слои, которые включаются в каждый слой большой предобученной модели; именно эти слои обучаются в процессе дообучения, в то время как веса трансформера остаются неизменными. Таким образом, с помощью адаптеров происходит кодирование специфичных для конкретного задания репрезентаций в слоях предобученной модели:

<p align="center">
  <img src="https://dsworks.s3pd01.sbercloud.ru/aij2021/misc/adapters.png" width="60%">
</p>

Адаптеры располагаются инкапсулированно, имеют модульную природу, что позволяет легко сочетать их друг с другом: наслаивать или менять динамически в процессе дообучения, комбинируя несколько источников релевантной информации. Авторы отмечают, что стандартные подходы к мультизадачному обучению (multi-task learning, MTL) имеют следующие недостатки: «катастрофическое забывание», когда информация, выученная на предыдущих стадиях обучения «перезаписывается»; падение качества предсказаний для множества заданий при добавлении новых; сложности с балансировкой задач. 
Инкапсулированность адаптеров позволяет им выучивать репрезентации для разных задач, совместимые друг с другом, – несколько адаптеров могут быть скомбинированы, например, с помощью механизма внимания ([MAD-X: An Adapter-Based Framework for
Multi-Task Cross-Lingual Transfer](https://arxiv.org/pdf/2005.00052.pdf) `Pfeiffer et al., 2020`). Адаптеры обучаются отдельно друг от друга, благодаря чему отпадает необходимость использовать эвристики при сэмплировании датасетов для разных задач; разделение двух процессов – извлечения знания и его объединения – позволяет легко добавлять новые задачи и решает проблему «катастрофического забывания». Фреймворк [AdapterHub](https://adapterhub.ml/), построенный поверх библиотеки Transformers от Hugging Face, позволяет легко экспериментировать с адаптерами. 

10. [Conditionally Adaptive Multi-Task Learning: Improving Transfer Learning in NLP Using Fewer Parameters & Less Data](https://arxiv.org/abs/2009.09139) (CA-MTL, `Pilaut et al., 2020`) - для решения одновременно нескольких NLP задач в классическом Multi-Task сеттинге, авторы предлагают модифицированную архитектуру трансформеров: обучаются специфичные для задачи эмбеддинги и специальный слой Conditional Alignment, выравнивающий входные эмбеддинги для соответствующей задачи, а также в половине слоёв предобученной модели заморожены, в то время как в другой половине добавлены обучаемы специфичные к задаче Conditional Attention, Conditional Layer Normalization и аналогичный идее адаптеров Conditional Bottleneck модули. Такое архитектурное решение позволяет в отличие от адаптеров обучаться одновременно на нескольких датасетах, а не обучать каждый адаптер по отдельности, при этом оставляя большую часть параметров модели общей. Для решения проблемы, связанной с неоднородностью данных в Multi-Task датасетах, авторы предлагают сэмплировать в батч только те примеры, в которых модель наименее уверенна в своих предсказаниях (т.е. наибольшая энтропия Шэннона), эта идея называется Multi-Task Uncertainty Sampling. В итоге предложенная архитектура позвоялет добиться лучших результатов на GLUE и SuperGLUE датасетах, чем файн-тюнинг для каждой отдельной задачи (т.е. обучая всего 1.12x, а не 24x параметров) и показывает отличные результаты в zero-shot и few-shot сеттинге.

<p align="center">
  <img src="https://i.ibb.co/0t3LVY3/CA-MTL.png" width="60%">
</p>

